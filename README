COMS E6111 Advanced Database Systems - Project 1

a) Group members:

    Yu Wang (yw2684)
    Chia-Jung Lin (cl3295)



b) Files:

    /--+--README
       +--main.py
       +--search.py
       +--interface.py
       +--parser.py
       +--transcript_musk.txt
       +--transcript_gates.txt
       +--transcript_taj_mahal.txt



c) How to run:

    python main.py <bing account key> <precision> <query>
    where:
        * bing account key: the Bing Account Key used for searching
        * precision: a real number between 0 and 1
        * query: a list of words in single quotes


d) Internal design:

    Overall structure: Our program is mainly composed of four parts: search, parsing, judgement, and query expansion.

    main.py: The entry point of the program. At the beginning of the routine, the query term list is processed by the
    search engine to form the request to the Bing server. In our setting, the result of the search from the Bing server
    will contain top-10 relevant web sites and be of XML format. The XML object is then parsed to get the information
    for users to decide whether each result is indeed relevant or not. After the judgement process is done, the program
    terminates if the desired relevance of the result is met or there is totally no relevant result. However, when there
    are relevant results but the relevance requirement is not met, the routine must be redone to get more relevant
    results. For the next routine, we pass the entire judgement result including the content of search results to the
    query expansion module which can compute the best fit words for the next round. The routine is then repeated until
    the relevance requirement is met.

    Computation.py: Contain some vector calculation methods that are used in the query expansion calculation

    Search_engine.py: Format the query url that is used by Bing API and get the result back

    Xml_parser.py: Parse the XML result returned by Bing so that we can retrieve the part of information
    that we are interested in

    QueryExpansion.py: Contain the query expansion algorithm which will be explained in detail in part(e)

    Document.py: Define a class for representing each document returned by the Bing Search API




e) Details of query modification:

The query modification algorithm is composed of the following parts:
1. remove punctuations and stopwords
        When calculating weights, we ignore the stopwords that are listed in NLTK package. We keep the ones that are included in query, if there is any. 

2. Give different weights to title and description
        From our observation, some words that frequently appear in description tend to lead the query to another topic that is somehow related to the original topic. Thus, we lower the weight in description to lower the chance of deviation. We set topic weight to 1.2 and description weight to 0.9. The weights are set emperically.

3. Compute tf-idf weight for document vector
        In our algorithm, tf is the normalized term frequency in the document and idf(t) = log N/M(t), where M is the
    number of documents that contain term t. And then we compute tfidf = tf * idf.

4. normalize document vector
        We take the normalized term frequency instead of the original term frequency. This is calculated by dividing
    the original term frequency by the length of the document.

5. Rocchio algorithm
        The key part of our query modification algorithm is Rocchio algorithm, which is also the most popular
    algorithm in query expansion. The new vector is calculated by:
                        Q1 = alpha*Q0 + beta*sum(R/n1) - gamma*sum(NR/n2)
    We set alpha=1, beta=0.8, c=0.15. The value of alpha and gamma is the same as the suggested value from the original algorithm. We raised bata by 0.8 after experiments.

6. Final evaluation (reorder)




f) Bing Search Account Key: KtKgk8Mo5p6/rJE0FnlmA8qKVi1F7kS3OQbxik1ZnCg



g) Additional information:

1. Parsing (stemming):
        
    We considered using stemming technique at first. However, stemming actually makes



2. Result evaluation:
        We ran our program the with the three examples "musk", "gates" and "columbia", the program can achieve a
    precision of 0.9 after 1, 1 and 2 iterations respectively, which is better than the reference program.

        In addition to the relevance judgement, we also check the augmented query terms computed with our method.
    Unfortunately, because the amount of data is rather small, we cannot evaluate the quality statistically. However,
    we compare our augmented terms with the result of the reference program, we are able to claim that our method is at
    least parallel to the reference program. For example, with the query, 'Big Apple', both programs could augment the
    query with 'city york'.

        In order to improve on the performance, the first thing we can do should be rearranging word order as mentioned
    above. Nevertheless, arbitrarily changing the order based on statistically unreliable data could produce different
    results. Therefore we stay with the solution before we can come up with a better way in the future.



h) Reference

[1] A Survey of Automatic Query Expansion in Information Retrieval, CLAUDIO CARPINETO and GIOVANNI ROMANO,
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.307.8469&rep=rep1&type=pdf

[2] RELEVANCE FEEDBACK AND OTHER QUERY MODIFICATION TECHNIQUES, Donna Harman,
http://orion.lcg.ufrj.br/Dr.Dobbs/books/book5/chap11.htm